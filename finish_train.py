import os
import cv2
import numpy as np
import logging
import h5py
import pickle
import gc
from deepface import DeepFace
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from concurrent.futures import ThreadPoolExecutor
from facenet_pytorch import MTCNN
from PIL import Image
import sqlite3
import json
from db import get_training_data_summary
import sys
import time

def clear_log_file():
    """X√≥a n·ªôi dung file training.log."""
    with open('training.log', 'w') as f:
        f.write('')
    logging.info("ƒê√£ x√≥a n·ªôi dung file training.log")

# Thi·∫øt l·∫≠p logging
logging.basicConfig(
    filename='training.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def ensure_directories():
    """T·∫°o c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt."""
    os.makedirs('processed_faces', exist_ok=True)
    os.makedirs('models', exist_ok=True)
    logging.info("ƒê√£ t·∫°o c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt")

def clear_processed_faces():
    """X√≥a th∆∞ m·ª•c processed_faces."""
    import shutil
    if os.path.exists('processed_faces'):
        shutil.rmtree('processed_faces')
    os.makedirs('processed_faces')
    logging.info("ƒê√£ x√≥a v√† t·∫°o l·∫°i th∆∞ m·ª•c processed_faces")

def smart_extract_and_save_faces_from_db(target_size=(160, 160)):
    """
    Tr√≠ch xu·∫•t khu√¥n m·∫∑t t·ª´ ·∫£nh v√† l∆∞u v√†o processed_faces m·ªôt c√°ch th√¥ng minh.
    Ch·ªâ x·ª≠ l√Ω l·∫°i ·∫£nh ƒë√£ thay ƒë·ªïi ho·∫∑c ch∆∞a ƒë∆∞·ª£c x·ª≠ l√Ω.
    """
    mtcnn = MTCNN(
        image_size=target_size[0],
        margin=30,
        min_face_size=50,
        thresholds=[0.7, 0.8, 0.9],
        device='cpu'
    )
    
    processed_faces_dir = 'processed_faces'
    os.makedirs(processed_faces_dir, exist_ok=True)
    
    # L·∫•y danh s√°ch ·∫£nh t·ª´ DB
    conn = sqlite3.connect('database.db')
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    cur.execute('''
        SELECT users.user_id, users.full_name, face_profiles.image_path
        FROM face_profiles
        JOIN users ON face_profiles.user_id = users.user_id
    ''')
    data = cur.fetchall()
    conn.close()
    
    total_images = len(data)
    total_processed = 0
    total_skipped = 0
    total_failed = 0
    user_id_to_fullname = {}
    
    logging.info(f"B·∫Øt ƒë·∫ßu x·ª≠ l√Ω {total_images} ·∫£nh...")
    
    for idx, row in enumerate(data, 1):
        user_id = row['user_id']
        full_name = row['full_name']
        user_id_to_fullname[str(user_id)] = full_name
        image_path = row['image_path']
        
        # T·∫°o ƒë∆∞·ªùng d·∫´n output
        output_person_dir = os.path.join(processed_faces_dir, str(user_id))
        os.makedirs(output_person_dir, exist_ok=True)
        output_filename = f"processed_{os.path.basename(image_path)}"
        output_path = os.path.join(output_person_dir, output_filename)
        
        # Ki·ªÉm tra xem ·∫£nh ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ch∆∞a v√† c√≥ c·∫ßn x·ª≠ l√Ω l·∫°i kh√¥ng
        need_process = True
        if os.path.exists(output_path):
            # So s√°nh th·ªùi gian s·ª≠a ƒë·ªïi
            original_mtime = os.path.getmtime(image_path)
            processed_mtime = os.path.getmtime(output_path)
            
            if processed_mtime >= original_mtime:
                # ·∫¢nh ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v√† kh√¥ng thay ƒë·ªïi
                need_process = False
                total_skipped += 1
        
        if need_process:
            try:
                img = Image.open(image_path).convert('RGB')
                face = mtcnn(img)
                if face is not None:
                    face = face.permute(1, 2, 0).numpy()
                    face = (face - face.min()) / (face.max() - face.min() + 1e-8)
                    face = (face * 255.0).astype(np.uint8)
                    face_pil = Image.fromarray(face)
                    face_pil.save(output_path)
                    total_processed += 1
                else:
                    logging.warning(f"Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t trong ·∫£nh: {image_path}")
                    total_failed += 1
            except Exception as e:
                logging.error(f"L·ªói x·ª≠ l√Ω ·∫£nh {image_path}: {e}")
                total_failed += 1
                continue
        
        # C·∫≠p nh·∫≠t ti·∫øn ƒë·ªô
        if idx % 20 == 0 or idx == total_images:
            percent = round((idx / total_images) * 50) if total_images else 0
            logging.info(f"Ti·∫øn tr√¨nh: {idx}/{total_images} ({percent}%)")
            print(f"Ti·∫øn tr√¨nh: {idx}/{total_images} ({percent}%)", flush=True)
    
    logging.info(f"Ho√†n th√†nh x·ª≠ l√Ω ·∫£nh:")
    logging.info(f"- ·∫¢nh m·ªõi x·ª≠ l√Ω: {total_processed}")
    logging.info(f"- ·∫¢nh ƒë√£ c√≥ (b·ªè qua): {total_skipped}")
    logging.info(f"- ·∫¢nh th·∫•t b·∫°i: {total_failed}")
    logging.info(f"Ti·∫øn tr√¨nh: (50%)")
    print(f"Ti·∫øn tr√¨nh: Ho√†n th√†nh x·ª≠ l√Ω ·∫£nh (50%)", flush=True)
    
    # L∆∞u √°nh x·∫° ra file
    with open('user_id_to_fullname.json', 'w', encoding='utf-8') as f:
        json.dump(user_id_to_fullname, f, ensure_ascii=False)
    
    return processed_faces_dir

def process_batch(batch, embedding_model='Facenet512'):
    """X·ª≠ l√Ω batch ·∫£nh v·ªõi FaceNet-512d."""
    batch_embeddings = []
    
    try:
        for img in batch:
            embedding_result = DeepFace.represent(
                img,
                model_name=embedding_model,
                enforce_detection=False,
                detector_backend='skip',
                align=False,
                normalization='base',
                anti_spoofing=False
            )[0]
            
            embedding = embedding_result['embedding']
            batch_embeddings.append(embedding)
            
    except Exception as e:
        logging.error(f"L·ªói x·ª≠ l√Ω batch: {str(e)}")
        return []
        
    return batch_embeddings

def create_training_data(
    processed_faces_dir,
    output_train_file='models/train_FN.h5',
    embedding_model='Facenet512',
    batch_size=4,
    test_size=0.2,
    random_state=42,
    target_size=(160, 160)
):
    """
    T·∫°o d·ªØ li·ªáu train t·ª´ ·∫£nh khu√¥n m·∫∑t ƒë√£ ƒë∆∞·ª£c c·∫Øt.
    Args:
        embedding_model: 'Facenet' (128 chi·ªÅu) ho·∫∑c 'Facenet512' (512 chi·ªÅu)
        batch_size: K√≠ch th∆∞·ªõc batch, ƒë·ªÅ xu·∫•t 4 cho Raspberry Pi 5
    """
    os.makedirs(os.path.dirname(output_train_file), exist_ok=True)
    
    embeddings = []
    labels = []
    failed_images = []
    
    if embedding_model not in ['Facenet', 'Facenet512']:
        raise ValueError("embedding_model ph·∫£i l√† 'Facenet' ho·∫∑c 'Facenet512'")
    
    try:
        person_dirs = [d for d in os.listdir(processed_faces_dir)
                      if os.path.isdir(os.path.join(processed_faces_dir, d))]
        
        if not person_dirs:
            raise ValueError("Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c ng∆∞·ªùi n√†o")
            
        logging.info(f"T√¨m th·∫•y {len(person_dirs)} th∆∞ m·ª•c ng∆∞·ªùi")
        
        with open('user_id_to_fullname.json', 'r', encoding='utf-8') as f:
            user_id_to_fullname = json.load(f)
        
        total_embedding_images = 0
        for person_name in person_dirs:
            person_path = os.path.join(processed_faces_dir, person_name)
            logging.info(f"ƒêang x·ª≠ l√Ω th∆∞ m·ª•c: {person_name}")
            image_files = [
                f for f in os.listdir(person_path)
                if f.startswith(('processed_', 'augmented_'))
            ]
            if len(image_files) < 5:
                logging.warning(f"Th∆∞ m·ª•c {person_name} c√≥ √≠t h∆°n 5 ·∫£nh, b·ªè qua")
                continue
            total_embedding_images += len(image_files)
        # Reset l·∫°i bi·∫øn ƒë·∫øm
        embedding_processed = 0
        
        for person_name in person_dirs:
            person_path = os.path.join(processed_faces_dir, person_name)
            logging.info(f"ƒêang x·ª≠ l√Ω th∆∞ m·ª•c: {person_name}")
            image_files = [
                f for f in os.listdir(person_path)
                if f.startswith(('processed_', 'augmented_'))
            ]
            if len(image_files) < 5:
                continue
            batches = [image_files[i:i + batch_size] for i in range(0, len(image_files), batch_size)]
            for batch in batches:
                batch_images = []
                batch_paths = []
                for image_file in batch:
                    image_path = os.path.join(person_path, image_file)
                    try:
                        img = cv2.imread(image_path)
                        if img is None:
                            failed_images.append((image_file, "Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh"))
                            continue
                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                        img = img.astype(np.float32) / 255.0
                        batch_images.append(img)
                        batch_paths.append(image_file)
                    except Exception as e:
                        failed_images.append((image_file, str(e)))
                        continue
                if batch_images:
                    with ThreadPoolExecutor(max_workers=2) as executor:  # Gi·∫£m t·∫£i h·ªá th·ªëng
                        batch_embeddings = executor.submit(process_batch, batch_images, embedding_model).result()
                    for embedding, image_file in zip(batch_embeddings, batch_paths):
                        if embedding:
                            embeddings.append(embedding)
                            label = user_id_to_fullname.get(person_name, person_name)
                            labels.append(label)
                        else:
                            failed_images.append((image_file, "L·ªói t·∫°o embedding"))
                        embedding_processed += 1
                        # C·∫≠p nh·∫≠t ti·∫øn ƒë·ªô sau m·ªói 20 ·∫£nh embedding, chia ƒë·ªÅu t·ª´ 50% ƒë·∫øn 100%
                        if embedding_processed % 20 == 0 or embedding_processed == total_embedding_images:
                            percent = 50 + round((embedding_processed / total_embedding_images) * 50) if total_embedding_images else 50
                            logging.info(f"Ti·∫øn tr√¨nh: {embedding_processed}/{total_embedding_images} ({percent}%)")
                            print(f"Ti·∫øn tr√¨nh: {embedding_processed}/{total_embedding_images} ({percent}%)", flush=True)
                    del batch_images
                    gc.collect()
        
        # Sau khi tr√≠ch xu·∫•t embedding xong, log 90%
        logging.info(f"Ti·∫øn tr√¨nh: (90%)")
        print(f"Ti·∫øn tr√¨nh: Ho√†n th√†nh tr√≠ch xu·∫•t embedding (90%)", flush=True)
        if embeddings:
            label_encoder = LabelEncoder()
            encoded_labels = label_encoder.fit_transform(labels)
            
            X_train, X_val, y_train, y_val = train_test_split(
                np.array(embeddings),
                encoded_labels,
                test_size=test_size,
                random_state=random_state,
                stratify=encoded_labels
            )
            
            X_train = X_train / np.linalg.norm(X_train, axis=1, keepdims=True)
            X_val = X_val / np.linalg.norm(X_val, axis=1, keepdims=True)
            
            with h5py.File(output_train_file, 'w') as f:
                f.create_dataset('embeddings', data=X_train)
                f.create_dataset('labels', data=y_train)
                f.create_dataset('X_val', data=X_val)
                f.create_dataset('y_val', data=y_val)
                f.attrs['embedding_model'] = embedding_model
                f.attrs['embedding_size'] = 512 if embedding_model == 'Facenet512' else 128
                
            with open(output_train_file.replace('.h5', '_label_encoder.pkl'), 'wb') as f_le:
                pickle.dump(label_encoder, f_le)
            
            logging.info(f"ƒê√£ t·∫°o file train t·∫°i: {output_train_file}")
            logging.info(f"S·ªë l∆∞·ª£ng ·∫£nh train: {len(y_train)}")
            logging.info(f"S·ªë l∆∞·ª£ng ·∫£nh validation: {len(y_val)}")
            
            if failed_images:
                logging.warning(f"T·ªïng s·ªë ·∫£nh l·ªói: {len(failed_images)}")
                with open('failed_images.log', 'w', encoding='utf-8') as f:
                    for img, reason in failed_images:
                        f.write(f"{img}: {reason}\n")
            # ƒê·∫£m b·∫£o in ra ƒë√∫ng 100% khi k·∫øt th√∫c
            logging.info(f"Ti·∫øn tr√¨nh: (100%)")
            print(f"Ti·∫øn tr√¨nh: Ho√†n th√†nh t·∫°o file train (100%)", flush=True)
        else:
            raise ValueError("Kh√¥ng c√≥ d·ªØ li·ªáu khu√¥n m·∫∑t n√†o ƒë∆∞·ª£c x·ª≠ l√Ω.")
            
    except Exception as e:
        logging.error(f"L·ªói t·∫°o d·ªØ li·ªáu train: {str(e)}")
        raise

def main():
    try:
        start_time = time.time()
        # Gi·∫£m ∆∞u ti√™n CPU cho ti·∫øn tr√¨nh train
        try:
            os.nice(10)
        except Exception:
            pass
        # Ki·ªÉm tra argument d√≤ng l·ªánh
        mode = None
        if len(sys.argv) > 1:
            if '--smart' in sys.argv:
                mode = '1'
            elif '--all' in sys.argv:
                mode = '2'
        # Ki·ªÉm tra d·ªØ li·ªáu tr∆∞·ªõc khi train
        print("üîç Ki·ªÉm tra d·ªØ li·ªáu training...")
        
        # Import t·ª´ check_training_data ƒë·ªÉ tr√°nh tr√πng l·∫∑p
        from check_training_data import detect_mapping_errors
        
        # Ki·ªÉm tra c∆° b·∫£n
        summary = get_training_data_summary()
        if summary['total_users'] == 0:
            print("‚ùå Kh√¥ng c√≥ users n√†o trong database!")
            print("Vui l√≤ng th√™m users tr∆∞·ªõc khi train.")
            return
        
        if summary['total_images'] == 0:
            print("‚ùå Kh√¥ng c1√≥ ·∫£nh n√†o trong database!")
            print("Vui l√≤ng th√™m ·∫£nh tr∆∞·ªõc khi train.")
            return
        
        # Ki·ªÉm tra users c√≥ √≠t ·∫£nh
        if summary['users_with_few_images']:
            print("‚ö†Ô∏è  C·∫£nh b√°o: C√≥ users c√≥ √≠t h∆°n 5 ·∫£nh:")
            for user in summary['users_with_few_images']:
                print(f"  - {user['username']} ({user['image_count']} ·∫£nh)")
            print("C√°c users n√†y s·∫Ω b·ªã b·ªè qua khi train.")
        
        # Ki·ªÉm tra mapping errors
        mapping_results = detect_mapping_errors()
        if mapping_results['errors']:
            print("‚ùå Ph√°t hi·ªán l·ªói mapping:")
            for error in mapping_results['errors']:
                print(f"  - {error['type']}: {error['count']} l·ªói")
            print("Vui l√≤ng ch·∫°y: python fix_database.py ƒë·ªÉ s·ª≠a l·ªói")
            return
        
        print("‚úÖ D·ªØ li·ªáu h·ª£p l·ªá, b·∫Øt ƒë·∫ßu train...")
        print(f"üìä T·ªïng users: {summary['total_users']}, T·ªïng ·∫£nh: {summary['total_images']}")
        
        # H·ªèi ng∆∞·ªùi d√πng v·ªÅ c√°ch x·ª≠ l√Ω ·∫£nh
        if mode is None:
            print("\nüîÑ CH·ªåN C√ÅCH X·ª¨ L√ù ·∫¢NH:")
            print("1. Th√¥ng minh (ch·ªâ x·ª≠ l√Ω ·∫£nh ƒë√£ thay ƒë·ªïi) - Khuy·∫øn ngh·ªã")
            print("2. X·ª≠ l√Ω l·∫°i t·∫•t c·∫£ ·∫£nh")
            while True:
                choice = input("Ch·ªçn (1/2): ").strip()
                if choice in ['1', '2']:
                    break
                print("Vui l√≤ng ch·ªçn 1 ho·∫∑c 2")
        else:
            choice = mode
        clear_log_file()  # X√≥a log c≈© tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu
        ensure_directories()
        
        if choice == '1':
            # X·ª≠ l√Ω th√¥ng minh
            print("üöÄ S·ª≠ d·ª•ng x·ª≠ l√Ω th√¥ng minh...")
            processed_faces_dir = smart_extract_and_save_faces_from_db(target_size=(160, 160))
        else:
            # X·ª≠ l√Ω l·∫°i t·∫•t c·∫£
            print("üîÑ X·ª≠ l√Ω l·∫°i t·∫•t c·∫£ ·∫£nh...")
            clear_processed_faces()
            processed_faces_dir = smart_extract_and_save_faces_from_db(target_size=(160, 160))
        create_training_data(
            processed_faces_dir=processed_faces_dir,
            output_train_file="models/train_FN.h5",
            embedding_model='Facenet512',
            batch_size=4,
            test_size=0.2
        )
        
    except Exception as e:
        logging.error(f"L·ªói trong qu√° tr√¨nh train: {str(e)}")
        raise
    # Sau khi ho√†n th√†nh train (sau khi in ti·∫øn tr√¨nh 100%)
    end_time = time.time()
    elapsed = int(end_time - start_time)
    minutes = elapsed // 60
    seconds = elapsed % 60
    elapsed_str = f"{minutes} ph√∫t {seconds} gi√¢y"
    logging.info(f"Th·ªùi gian hu·∫•n luy·ªán: {elapsed_str}")
    print(f"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán: {elapsed_str}", flush=True)

if __name__ == "__main__":
    main()